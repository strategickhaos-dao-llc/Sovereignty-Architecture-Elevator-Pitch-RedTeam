"""
Obsidian Integration - Layer 5 of Self-Evolving Refinery
Bidirectional Learning from Vault - Obsidian becomes the agent's long-term memory
For her. Silent. Relentless. Self-improving.
"""

import asyncio
import hashlib
import json
import os
import re
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Set, Tuple

import structlog
from pydantic import BaseModel, Field
from watchdog.events import FileSystemEventHandler, FileModifiedEvent, FileCreatedEvent
from watchdog.observers import Observer

logger = structlog.get_logger()


class NoteType(Enum):
    """Types of Obsidian notes"""
    DISCOVERY = "discovery"
    HYPOTHESIS = "hypothesis"
    TREATMENT_OPTION = "treatment_option"
    PAPER_SUMMARY = "paper_summary"
    SYMPTOM_LOG = "symptom_log"
    RESEARCH_LOG = "research_log"
    GENERAL = "general"


@dataclass
class ObsidianNote:
    """Represents an Obsidian note"""
    path: str
    title: str
    content: str
    note_type: NoteType
    frontmatter: Dict[str, Any] = field(default_factory=dict)
    links: List[str] = field(default_factory=list)
    backlinks: List[str] = field(default_factory=list)
    tags: List[str] = field(default_factory=list)
    created_at: Optional[datetime] = None
    modified_at: Optional[datetime] = None
    checksum: str = ""

    def __post_init__(self):
        if not self.checksum:
            self.checksum = hashlib.sha256(self.content.encode()).hexdigest()[:16]


@dataclass
class SearchResult:
    """Result from vault search"""
    note: ObsidianNote
    score: float
    matched_content: str
    match_type: str  # "semantic", "dataview", "tag", "link"


@dataclass
class GraphNode:
    """Node in the knowledge graph"""
    note_path: str
    connections: List[str] = field(default_factory=list)
    connection_types: Dict[str, str] = field(default_factory=dict)  # path -> type


@dataclass
class StateUpdate:
    """Update to STATE.yaml"""
    key: str
    value: Any
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    source: str = "agent"


class NoteTemplate:
    """Template for generating notes"""

    DISCOVERY_TEMPLATE = """---
type: discovery
date: {date}
agent: {agent_id}
confidence: {confidence}
tags: {tags}
sources: {sources}
---

# {title}

## Summary
{summary}

## Key Findings
{findings}

## Evidence
{evidence}

## Implications
{implications}

## Related Notes
{related}

---
*Generated by Self-Evolving Refinery*
"""

    HYPOTHESIS_TEMPLATE = """---
type: hypothesis
date: {date}
agent: {agent_id}
status: {status}
priority: {priority}
tags: {tags}
---

# Hypothesis: {title}

## Statement
{statement}

## Rationale
{rationale}

## Supporting Evidence
{supporting}

## Contradicting Evidence
{contradicting}

## Testing Plan
{testing_plan}

## Expected Outcome
{expected_outcome}

## Related Notes
{related}

---
*Generated by Self-Evolving Refinery*
"""

    TREATMENT_OPTION_TEMPLATE = """---
type: treatment_option
date: {date}
agent: {agent_id}
status: {status}
safety_score: {safety_score}
efficacy_estimate: {efficacy_estimate}
tags: {tags}
---

# Treatment: {title}

## Overview
{overview}

## Mechanism of Action
{mechanism}

## Evidence Base
{evidence}

## Potential Benefits
{benefits}

## Risks and Side Effects
{risks}

## Dosage and Administration
{dosage}

## Cost Estimate
{cost}

## Next Steps
{next_steps}

## Related Notes
{related}

---
*Generated by Self-Evolving Refinery*
*Requires physician review before implementation*
"""

    @classmethod
    def get_template(cls, note_type: NoteType) -> str:
        """Get template for note type"""
        templates = {
            NoteType.DISCOVERY: cls.DISCOVERY_TEMPLATE,
            NoteType.HYPOTHESIS: cls.HYPOTHESIS_TEMPLATE,
            NoteType.TREATMENT_OPTION: cls.TREATMENT_OPTION_TEMPLATE
        }
        return templates.get(note_type, "")


class VaultWatcher(FileSystemEventHandler):
    """Watch Obsidian vault for changes"""

    def __init__(self, callback: Callable[[str, str], None], debounce_ms: int = 1000):
        self.callback = callback
        self.debounce_ms = debounce_ms
        self._pending_events: Dict[str, asyncio.Task] = {}

    def on_modified(self, event):
        if not event.is_directory and event.src_path.endswith(".md"):
            self._handle_event(event.src_path, "modified")

    def on_created(self, event):
        if not event.is_directory and event.src_path.endswith(".md"):
            self._handle_event(event.src_path, "created")

    def _handle_event(self, path: str, event_type: str):
        """Handle file event with debouncing"""
        if path in self._pending_events:
            self._pending_events[path].cancel()

        async def debounced_callback():
            await asyncio.sleep(self.debounce_ms / 1000)
            self.callback(path, event_type)

        loop = asyncio.get_event_loop()
        self._pending_events[path] = loop.create_task(debounced_callback())


class VaultReader:
    """Read from Obsidian vault"""

    def __init__(self, vault_path: str):
        self.vault_path = Path(vault_path)
        self._note_cache: Dict[str, ObsidianNote] = {}
        self._graph: Dict[str, GraphNode] = {}

    async def read_note(self, path: str) -> Optional[ObsidianNote]:
        """Read a specific note"""
        full_path = self.vault_path / path

        if not full_path.exists():
            return None

        try:
            content = full_path.read_text(encoding="utf-8")
            return self._parse_note(path, content)
        except Exception as e:
            logger.error("Failed to read note", path=path, error=str(e))
            return None

    def _parse_note(self, path: str, content: str) -> ObsidianNote:
        """Parse note content into ObsidianNote"""
        # Extract frontmatter
        frontmatter = self._extract_frontmatter(content)

        # Determine note type
        note_type = NoteType.GENERAL
        if frontmatter.get("type"):
            try:
                note_type = NoteType(frontmatter["type"])
            except ValueError:
                pass

        # Extract links
        links = self._extract_links(content)

        # Extract tags
        tags = self._extract_tags(content)
        if frontmatter.get("tags"):
            tags.extend(frontmatter["tags"] if isinstance(frontmatter["tags"], list) else [frontmatter["tags"]])

        # Extract title
        title_match = re.search(r"^#\s+(.+)$", content, re.MULTILINE)
        title = title_match.group(1) if title_match else Path(path).stem

        # Get file timestamps
        full_path = self.vault_path / path
        stat = full_path.stat()
        created_at = datetime.fromtimestamp(stat.st_ctime, tz=timezone.utc)
        modified_at = datetime.fromtimestamp(stat.st_mtime, tz=timezone.utc)

        return ObsidianNote(
            path=path,
            title=title,
            content=content,
            note_type=note_type,
            frontmatter=frontmatter,
            links=links,
            tags=list(set(tags)),
            created_at=created_at,
            modified_at=modified_at
        )

    def _extract_frontmatter(self, content: str) -> Dict[str, Any]:
        """Extract YAML frontmatter"""
        pattern = re.compile(r"^---\s*\n(.*?)\n---\s*\n", re.DOTALL)
        match = pattern.match(content)
        if match:
            try:
                import yaml
                return yaml.safe_load(match.group(1)) or {}
            except Exception:
                pass
        return {}

    def _extract_links(self, content: str) -> List[str]:
        """Extract wiki-style links"""
        pattern = re.compile(r"\[\[(.*?)(?:\|.*?)?\]\]")
        return pattern.findall(content)

    def _extract_tags(self, content: str) -> List[str]:
        """Extract tags"""
        pattern = re.compile(r"#([a-zA-Z0-9_/-]+)")
        return list(set(pattern.findall(content)))

    async def search_semantic(self, query: str, limit: int = 10) -> List[SearchResult]:
        """Semantic search across vault"""
        logger.info("Semantic search", query=query[:50], limit=limit)

        # Placeholder for actual semantic search using embeddings
        # Would use Qdrant or similar vector store

        results = []

        # Simple keyword search as fallback
        for path, note in self._note_cache.items():
            if query.lower() in note.content.lower():
                results.append(SearchResult(
                    note=note,
                    score=0.5,
                    matched_content=note.content[:200],
                    match_type="keyword"
                ))

        return sorted(results, key=lambda r: r.score, reverse=True)[:limit]

    async def search_dataview(self, query: str) -> List[SearchResult]:
        """Execute Dataview-style query"""
        logger.info("Dataview query", query=query[:50])

        # Parse simple Dataview queries
        # Example: "TABLE file.name WHERE type = discovery"

        results = []

        # Simple type-based filtering
        type_match = re.search(r'type\s*=\s*["\']?(\w+)["\']?', query, re.IGNORECASE)
        if type_match:
            target_type = type_match.group(1)
            for path, note in self._note_cache.items():
                if note.frontmatter.get("type") == target_type:
                    results.append(SearchResult(
                        note=note,
                        score=1.0,
                        matched_content=note.title,
                        match_type="dataview"
                    ))

        return results

    async def search_by_tag(self, tag: str) -> List[SearchResult]:
        """Search notes by tag"""
        results = []

        for path, note in self._note_cache.items():
            if tag in note.tags or tag.lstrip("#") in note.tags:
                results.append(SearchResult(
                    note=note,
                    score=1.0,
                    matched_content=note.title,
                    match_type="tag"
                ))

        return results

    async def traverse_graph(self, start_note: str, depth: int = 2) -> List[GraphNode]:
        """Traverse knowledge graph from a starting note"""
        visited: Set[str] = set()
        result: List[GraphNode] = []

        async def _traverse(path: str, current_depth: int):
            if path in visited or current_depth > depth:
                return

            visited.add(path)

            if path in self._graph:
                result.append(self._graph[path])

                for connection in self._graph[path].connections:
                    await _traverse(connection, current_depth + 1)

        await _traverse(start_note, 0)
        return result

    async def build_graph(self):
        """Build knowledge graph from vault"""
        logger.info("Building knowledge graph")

        self._graph.clear()

        # Scan all markdown files
        for md_file in self.vault_path.rglob("*.md"):
            rel_path = str(md_file.relative_to(self.vault_path))

            note = await self.read_note(rel_path)
            if note:
                self._note_cache[rel_path] = note

                self._graph[rel_path] = GraphNode(
                    note_path=rel_path,
                    connections=note.links,
                    connection_types={link: "link" for link in note.links}
                )

        # Build backlinks
        for path, node in self._graph.items():
            for link in node.connections:
                link_path = f"{link}.md" if not link.endswith(".md") else link
                if link_path in self._graph:
                    if path not in self._graph[link_path].connections:
                        self._graph[link_path].connections.append(path)
                        self._graph[link_path].connection_types[path] = "backlink"

        logger.info(
            "Knowledge graph built",
            nodes=len(self._graph),
            total_connections=sum(len(n.connections) for n in self._graph.values())
        )


class VaultWriter:
    """Write to Obsidian vault"""

    def __init__(self, vault_path: str, templates_dir: Optional[str] = None):
        self.vault_path = Path(vault_path)
        self.templates_dir = Path(templates_dir) if templates_dir else self.vault_path / "templates"

    async def write_note(
        self,
        note_type: NoteType,
        title: str,
        data: Dict[str, Any],
        folder: str = "Agent Discoveries"
    ) -> str:
        """Write a new note to the vault"""
        # Sanitize title for filename
        filename = re.sub(r'[^\w\s-]', '', title).strip().replace(' ', '_')
        date_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{filename}_{date_str}.md"

        # Ensure folder exists
        folder_path = self.vault_path / folder
        folder_path.mkdir(parents=True, exist_ok=True)

        # Generate content from template
        template = NoteTemplate.get_template(note_type)

        if template:
            content = self._fill_template(template, data)
        else:
            content = self._generate_generic_note(title, data)

        # Write file
        file_path = folder_path / filename
        file_path.write_text(content, encoding="utf-8")

        rel_path = str(file_path.relative_to(self.vault_path))
        logger.info("Note written", path=rel_path, type=note_type.value)

        return rel_path

    def _fill_template(self, template: str, data: Dict[str, Any]) -> str:
        """Fill template with data"""
        # Add current date
        data.setdefault("date", datetime.now().strftime("%Y-%m-%d"))

        # Format lists
        for key, value in data.items():
            if isinstance(value, list):
                data[key] = "\n".join(f"- {item}" for item in value)

        # Handle missing keys with empty strings
        import string

        class SafeFormatter(string.Formatter):
            def get_value(self, key, args, kwargs):
                if isinstance(key, str):
                    return kwargs.get(key, "")
                return super().get_value(key, args, kwargs)

        formatter = SafeFormatter()
        return formatter.format(template, **data)

    def _generate_generic_note(self, title: str, data: Dict[str, Any]) -> str:
        """Generate generic note without template"""
        content = f"""---
date: {datetime.now().strftime("%Y-%m-%d")}
type: general
---

# {title}

"""
        for key, value in data.items():
            if key not in ["title", "date", "type"]:
                if isinstance(value, list):
                    content += f"\n## {key.replace('_', ' ').title()}\n"
                    for item in value:
                        content += f"- {item}\n"
                else:
                    content += f"\n## {key.replace('_', ' ').title()}\n{value}\n"

        return content

    async def update_note(self, path: str, updates: Dict[str, Any]) -> bool:
        """Update an existing note"""
        full_path = self.vault_path / path

        if not full_path.exists():
            logger.error("Note not found", path=path)
            return False

        try:
            content = full_path.read_text(encoding="utf-8")

            # Update frontmatter
            if updates.get("frontmatter"):
                content = self._update_frontmatter(content, updates["frontmatter"])

            # Append content
            if updates.get("append"):
                content += f"\n\n{updates['append']}"

            full_path.write_text(content, encoding="utf-8")
            logger.info("Note updated", path=path)
            return True

        except Exception as e:
            logger.error("Failed to update note", path=path, error=str(e))
            return False

    def _update_frontmatter(self, content: str, updates: Dict[str, Any]) -> str:
        """Update frontmatter in content"""
        import yaml

        pattern = re.compile(r"^---\s*\n(.*?)\n---\s*\n", re.DOTALL)
        match = pattern.match(content)

        if match:
            current_fm = yaml.safe_load(match.group(1)) or {}
            current_fm.update(updates)
            new_fm = yaml.dump(current_fm, default_flow_style=False)
            content = pattern.sub(f"---\n{new_fm}---\n", content, count=1)
        else:
            # Add frontmatter
            fm = yaml.dump(updates, default_flow_style=False)
            content = f"---\n{fm}---\n\n{content}"

        return content

    async def create_link(self, from_note: str, to_note: str, link_text: Optional[str] = None):
        """Create a link between notes"""
        full_path = self.vault_path / from_note

        if not full_path.exists():
            logger.error("Source note not found", path=from_note)
            return False

        content = full_path.read_text(encoding="utf-8")

        to_name = Path(to_note).stem
        link = f"[[{to_name}|{link_text}]]" if link_text else f"[[{to_name}]]"

        # Add to Related Notes section if it exists, otherwise append
        if "## Related Notes" in content:
            content = content.replace(
                "## Related Notes",
                f"## Related Notes\n- {link}"
            )
        else:
            content += f"\n\n## Related Notes\n- {link}"

        full_path.write_text(content, encoding="utf-8")
        return True


class StateManager:
    """Manage STATE.yaml file"""

    def __init__(self, vault_path: str, state_file: str = "STATE.yaml"):
        self.vault_path = Path(vault_path)
        self.state_file = self.vault_path / state_file
        self._state: Dict[str, Any] = {}
        self._history: List[StateUpdate] = []

    async def load(self):
        """Load state from file"""
        if self.state_file.exists():
            try:
                import yaml
                self._state = yaml.safe_load(self.state_file.read_text()) or {}
                logger.info("State loaded", keys=len(self._state))
            except Exception as e:
                logger.error("Failed to load state", error=str(e))
                self._state = {}

    async def save(self):
        """Save state to file"""
        try:
            import yaml

            # Create backup
            if self.state_file.exists():
                backup_path = self.state_file.with_suffix(".yaml.bak")
                backup_path.write_text(self.state_file.read_text())

            self.state_file.write_text(yaml.dump(self._state, default_flow_style=False))
            logger.info("State saved")
        except Exception as e:
            logger.error("Failed to save state", error=str(e))

    async def get(self, key: str, default: Any = None) -> Any:
        """Get state value"""
        return self._state.get(key, default)

    async def set(self, key: str, value: Any, source: str = "agent"):
        """Set state value"""
        self._state[key] = value
        self._history.append(StateUpdate(key=key, value=value, source=source))
        await self.save()

    async def update(self, updates: Dict[str, Any], source: str = "agent"):
        """Update multiple state values"""
        for key, value in updates.items():
            self._state[key] = value
            self._history.append(StateUpdate(key=key, value=value, source=source))
        await self.save()


class ObsidianIntegration:
    """
    Main Obsidian Integration - Layer 5 of Self-Evolving Refinery
    Bidirectional learning from vault
    """

    def __init__(
        self,
        vault_path: str,
        watch_mode: bool = True,
        debounce_ms: int = 1000,
        full_reindex_interval: int = 86400
    ):
        self.vault_path = Path(vault_path)
        self.watch_mode = watch_mode
        self.debounce_ms = debounce_ms
        self.full_reindex_interval = full_reindex_interval

        self.reader = VaultReader(vault_path)
        self.writer = VaultWriter(vault_path)
        self.state_manager = StateManager(vault_path)

        self._watcher: Optional[Observer] = None
        self._change_callbacks: List[Callable[[str, str], None]] = []

        logger.info("Obsidian Integration initialized", vault_path=vault_path)

    async def initialize(self):
        """Initialize the integration"""
        # Load state
        await self.state_manager.load()

        # Build initial graph
        await self.reader.build_graph()

        # Start watcher if enabled
        if self.watch_mode:
            self._start_watcher()

        logger.info("Obsidian Integration ready")

    def _start_watcher(self):
        """Start file system watcher"""
        handler = VaultWatcher(
            callback=self._on_file_change,
            debounce_ms=self.debounce_ms
        )

        self._watcher = Observer()
        self._watcher.schedule(handler, str(self.vault_path), recursive=True)
        self._watcher.start()

        logger.info("Vault watcher started")

    def _on_file_change(self, path: str, event_type: str):
        """Handle file change event"""
        logger.debug("File changed", path=path, event_type=event_type)

        for callback in self._change_callbacks:
            try:
                callback(path, event_type)
            except Exception as e:
                logger.error("Change callback failed", error=str(e))

    def register_change_callback(self, callback: Callable[[str, str], None]):
        """Register callback for file changes"""
        self._change_callbacks.append(callback)

    async def read_note(self, path: str) -> Optional[ObsidianNote]:
        """Read a note from the vault"""
        return await self.reader.read_note(path)

    async def search(
        self,
        query: str,
        search_type: str = "semantic",
        limit: int = 10
    ) -> List[SearchResult]:
        """Search the vault"""
        if search_type == "semantic":
            return await self.reader.search_semantic(query, limit)
        elif search_type == "dataview":
            return await self.reader.search_dataview(query)
        elif search_type == "tag":
            return await self.reader.search_by_tag(query)
        else:
            return await self.reader.search_semantic(query, limit)

    async def write_discovery(
        self,
        agent_id: str,
        title: str,
        summary: str,
        findings: List[str],
        evidence: List[str],
        implications: List[str],
        confidence: float,
        tags: List[str],
        sources: List[str]
    ) -> str:
        """Write a discovery note"""
        data = {
            "agent_id": agent_id,
            "title": title,
            "summary": summary,
            "findings": findings,
            "evidence": evidence,
            "implications": implications,
            "confidence": confidence,
            "tags": tags,
            "sources": sources,
            "related": []
        }

        path = await self.writer.write_note(
            NoteType.DISCOVERY,
            title,
            data,
            folder="Agent Discoveries"
        )

        # Auto-link to related notes
        await self._auto_link(path, tags + sources)

        return path

    async def write_hypothesis(
        self,
        agent_id: str,
        title: str,
        statement: str,
        rationale: str,
        supporting: List[str],
        contradicting: List[str],
        testing_plan: str,
        expected_outcome: str,
        priority: str = "medium",
        tags: List[str] = None
    ) -> str:
        """Write a hypothesis note"""
        data = {
            "agent_id": agent_id,
            "title": title,
            "statement": statement,
            "rationale": rationale,
            "supporting": supporting,
            "contradicting": contradicting,
            "testing_plan": testing_plan,
            "expected_outcome": expected_outcome,
            "status": "proposed",
            "priority": priority,
            "tags": tags or [],
            "related": []
        }

        return await self.writer.write_note(
            NoteType.HYPOTHESIS,
            f"Hypothesis - {title}",
            data,
            folder="Hypotheses"
        )

    async def write_treatment_option(
        self,
        agent_id: str,
        title: str,
        overview: str,
        mechanism: str,
        evidence: List[str],
        benefits: List[str],
        risks: List[str],
        dosage: str,
        cost: str,
        next_steps: List[str],
        safety_score: float,
        efficacy_estimate: float,
        tags: List[str] = None
    ) -> str:
        """Write a treatment option note"""
        data = {
            "agent_id": agent_id,
            "title": title,
            "overview": overview,
            "mechanism": mechanism,
            "evidence": evidence,
            "benefits": benefits,
            "risks": risks,
            "dosage": dosage,
            "cost": cost,
            "next_steps": next_steps,
            "status": "under_review",
            "safety_score": safety_score,
            "efficacy_estimate": efficacy_estimate,
            "tags": tags or [],
            "related": []
        }

        return await self.writer.write_note(
            NoteType.TREATMENT_OPTION,
            f"Treatment - {title}",
            data,
            folder="Treatment Options"
        )

    async def _auto_link(self, note_path: str, keywords: List[str]):
        """Automatically link to related notes"""
        for keyword in keywords:
            results = await self.reader.search_semantic(keyword, limit=5)
            for result in results:
                if result.note.path != note_path and result.score > 0.7:
                    await self.writer.create_link(note_path, result.note.path)

    async def learn_from_note(self, path: str) -> Dict[str, Any]:
        """Extract learnings from a note"""
        note = await self.read_note(path)
        if not note:
            return {"error": "Note not found"}

        learnings = {
            "title": note.title,
            "type": note.note_type.value,
            "key_concepts": [],
            "mentioned_entities": [],
            "outcomes": [],
            "lessons": []
        }

        # Extract key concepts (simplified)
        # In production, would use NLP

        # Check for outcome information
        if "failed" in note.content.lower() or "didn't work" in note.content.lower():
            learnings["lessons"].append({
                "type": "negative_outcome",
                "content": note.content[:500]
            })
        elif "success" in note.content.lower() or "worked" in note.content.lower():
            learnings["lessons"].append({
                "type": "positive_outcome",
                "content": note.content[:500]
            })

        return learnings

    async def update_state(self, key: str, value: Any):
        """Update state"""
        await self.state_manager.set(key, value)

    async def get_state(self, key: str, default: Any = None) -> Any:
        """Get state value"""
        return await self.state_manager.get(key, default)

    async def get_vault_statistics(self) -> Dict[str, Any]:
        """Get vault statistics"""
        return {
            "total_notes": len(self.reader._note_cache),
            "graph_nodes": len(self.reader._graph),
            "note_types": {},
            "tags": {}
        }

    async def shutdown(self):
        """Shutdown the integration"""
        if self._watcher:
            self._watcher.stop()
            self._watcher.join()

        logger.info("Obsidian Integration shutdown")


# Factory function
async def create_obsidian_integration(config_path: str) -> ObsidianIntegration:
    """Create Obsidian Integration from YAML config"""
    import yaml

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    layer_5_config = config.get("core_architecture", {}).get("refinery_layers", {}).get("layer_5_obsidian_integration", {})

    # Get vault path from environment or config
    vault_path = os.environ.get("OBSIDIAN_VAULT_PATH", "/data/obsidian")

    indexing_config = layer_5_config.get("read_operations", {}).get("indexing", {})

    integration = ObsidianIntegration(
        vault_path=vault_path,
        watch_mode=indexing_config.get("watch_mode", True),
        debounce_ms=indexing_config.get("debounce_ms", 1000),
        full_reindex_interval=indexing_config.get("full_reindex_interval", 86400)
    )

    await integration.initialize()

    return integration
