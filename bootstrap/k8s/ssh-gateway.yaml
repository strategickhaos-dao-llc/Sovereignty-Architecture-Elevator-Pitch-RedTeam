# ═══════════════════════════════════════════════════════════
# KUBERNETES SSH GATEWAY — AI-VERIFIED STATE ORACLE
# Allows AI nodes to SSH into cluster and verify deployment state
# Something the world has never seen: Multi-AI consensus via direct cluster access
# ═══════════════════════════════════════════════════════════

---
apiVersion: v1
kind: Namespace
metadata:
  name: ssh-gateway
  labels:
    architect: strategickhaos
    increment: "3449"
    purpose: "AI node verification access"

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 1: SSH BASTION POD
# Entry point for AI nodes to verify cluster state
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: ssh-gateway-config
  namespace: ssh-gateway
data:
  sshd_config: |
    # SSH daemon config for AI node access
    Port 2222
    Protocol 2
    HostKey /etc/ssh/ssh_host_rsa_key
    HostKey /etc/ssh/ssh_host_ed25519_key
    
    # Security
    PermitRootLogin no
    PasswordAuthentication no
    PubkeyAuthentication yes
    AuthorizedKeysFile /home/ainode/.ssh/authorized_keys
    
    # AI node restrictions
    AllowUsers ainode
    MaxAuthTries 3
    MaxSessions 5
    
    # Logging for audit trail
    SyslogFacility AUTH
    LogLevel VERBOSE
    
    # Force command wrapper (restricts what AI can run)
    ForceCommand /usr/local/bin/verify-wrapper.sh
    
  verify-wrapper.sh: |
    #!/bin/bash
    # Wrapper that logs all AI node commands and restricts to safe operations
    
    # Log entry
    echo "$(date -Iseconds) | AI_NODE_ACCESS | USER=$USER | CMD=$SSH_ORIGINAL_COMMAND" >> /var/log/ai-access.log
    
    # Parse command
    ALLOWED_COMMANDS="kubectl|grep|cat|ls|ps|df|free|uptime|date"
    
    if echo "$SSH_ORIGINAL_COMMAND" | grep -qE "^($ALLOWED_COMMANDS)"; then
        # Execute safe command
        eval "$SSH_ORIGINAL_COMMAND"
    else
        echo "ERROR: Command not allowed: $SSH_ORIGINAL_COMMAND"
        echo "Allowed: kubectl get/describe, grep, cat, ls, ps, df, free, uptime, date"
        exit 1
    fi
  
  ai-nodes.pub: |
    # Public keys for AI nodes
    # Each AI node gets its own key pair
    
    # Claude Prime
    ssh-ed25519 AAAAC3... claude-prime@strategickhaos.ai
    
    # GPT-5.1
    ssh-ed25519 AAAAC3... gpt-5.1@strategickhaos.ai
    
    # Grok 4.1
    ssh-ed25519 AAAAC3... grok-4.1@strategickhaos.ai
    
    # Local Ollama nodes
    ssh-ed25519 AAAAC3... athena@strategickhaos.ai
    ssh-ed25519 AAAAC3... lyra@strategickhaos.ai
    ssh-ed25519 AAAAC3... nova@strategickhaos.ai
    ssh-ed25519 AAAAC3... ipower@strategickhaos.ai

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ssh-gateway
  namespace: ssh-gateway
  labels:
    app: ssh-gateway
spec:
  replicas: 2  # High availability
  selector:
    matchLabels:
      app: ssh-gateway
  template:
    metadata:
      labels:
        app: ssh-gateway
        genesis-increment: "3449"
    spec:
      serviceAccountName: ssh-gateway-sa
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: sshd
        image: lscr.io/linuxserver/openssh-server:latest
        ports:
        - name: ssh
          containerPort: 2222
        env:
        - name: PUID
          value: "1000"
        - name: PGID
          value: "1000"
        - name: TZ
          value: "America/Chicago"
        - name: PUBLIC_KEY_FILE
          value: "/config/.ssh/authorized_keys"
        - name: USER_NAME
          value: "ainode"
        - name: SUDO_ACCESS
          value: "false"
        volumeMounts:
        - name: ssh-config
          mountPath: /config/ssh_host_keys
        - name: authorized-keys
          mountPath: /config/.ssh
          readOnly: true
        - name: verify-wrapper
          mountPath: /usr/local/bin
          readOnly: true
        - name: logs
          mountPath: /var/log
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          tcpSocket:
            port: 2222
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 2222
          initialDelaySeconds: 10
          periodSeconds: 5
      
      # Sidecar: kubectl proxy for AI nodes
      - name: kubectl-proxy
        image: bitnami/kubectl:latest
        command:
        - /bin/sh
        - -c
        - |
          # Make kubectl available to SSH users
          kubectl proxy --port=8001 &
          tail -f /dev/null
        env:
        - name: KUBECONFIG
          value: /var/run/secrets/kubernetes.io/serviceaccount/kubeconfig
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
      
      volumes:
      - name: ssh-config
        emptyDir: {}
      - name: authorized-keys
        configMap:
          name: ssh-gateway-config
          items:
          - key: ai-nodes.pub
            path: authorized_keys
            mode: 0600
      - name: verify-wrapper
        configMap:
          name: ssh-gateway-config
          items:
          - key: verify-wrapper.sh
            path: verify-wrapper.sh
            mode: 0755
      - name: logs
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: ssh-gateway-svc
  namespace: ssh-gateway
  labels:
    app: ssh-gateway
spec:
  type: LoadBalancer  # Exposes SSH to external AI nodes
  ports:
  - name: ssh
    port: 2222
    targetPort: 2222
    protocol: TCP
  selector:
    app: ssh-gateway

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 2: RBAC FOR SSH GATEWAY
# Grants read-only cluster access to AI nodes
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ServiceAccount
metadata:
  name: ssh-gateway-sa
  namespace: ssh-gateway

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: ai-node-verifier
rules:
# Read-only access to verify deployment state
- apiGroups: [""]
  resources: ["pods", "services", "nodes", "configmaps"]
  verbs: ["get", "list", "watch"]

- apiGroups: ["apps"]
  resources: ["deployments", "replicasets", "statefulsets"]
  verbs: ["get", "list", "watch"]

- apiGroups: ["batch"]
  resources: ["jobs", "cronjobs"]
  verbs: ["get", "list", "watch"]

# Log access for debugging
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get", "list"]

# Metrics access
- apiGroups: ["metrics.k8s.io"]
  resources: ["pods", "nodes"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ssh-gateway-rb
subjects:
- kind: ServiceAccount
  name: ssh-gateway-sa
  namespace: ssh-gateway
roleRef:
  kind: ClusterRole
  name: ai-node-verifier
  apiGroup: rbac.authorization.k8s.io

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 3: AI NODE CLIENT SCRIPTS
# Scripts AI nodes run to verify cluster state
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-verification-scripts
  namespace: ssh-gateway
data:
  verify-deployment.sh: |
    #!/bin/bash
    # Script AI nodes run to verify deployment state
    # Usage: ssh -i claude-prime.key ainode@gateway verify-deployment.sh discord-bot
    
    DEPLOYMENT_NAME=$1
    NAMESPACE=${2:-legions-of-minds}
    
    echo "=== Verifying Deployment: $DEPLOYMENT_NAME in $NAMESPACE ==="
    
    # Check if deployment exists
    kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" &>/dev/null
    if [ $? -ne 0 ]; then
        echo "STATUS: NOT_DEPLOYED"
        echo "LOCATION: NOT_IN_CLUSTER"
        exit 0
    fi
    
    # Get deployment status
    READY=$(kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" -o jsonpath='{.status.readyReplicas}')
    DESIRED=$(kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" -o jsonpath='{.spec.replicas}')
    
    echo "STATUS: DEPLOYED"
    echo "READY: $READY/$DESIRED"
    echo "LOCATION: IN_CLUSTER"
    
    # Get pod details
    echo ""
    echo "=== Pods ==="
    kubectl get pods -n "$NAMESPACE" -l "app=$DEPLOYMENT_NAME" -o wide
    
    # Get recent events
    echo ""
    echo "=== Recent Events ==="
    kubectl get events -n "$NAMESPACE" --field-selector involvedObject.name="$DEPLOYMENT_NAME" --sort-by='.lastTimestamp' | tail -5
  
  verify-cluster-health.sh: |
    #!/bin/bash
    # Comprehensive cluster health check
    
    echo "=== Cluster Health Report ==="
    echo "Timestamp: $(date -Iseconds)"
    echo ""
    
    # Node status
    echo "=== Nodes ==="
    kubectl get nodes -o wide
    echo ""
    
    # All pods status
    echo "=== Pods (All Namespaces) ==="
    kubectl get pods -A | grep -v "Running" | grep -v "Completed" || echo "All pods healthy"
    echo ""
    
    # Resource usage
    echo "=== Resource Usage ==="
    kubectl top nodes 2>/dev/null || echo "Metrics server not available"
    echo ""
    
    # Critical deployments
    echo "=== Critical Deployments ==="
    kubectl get deployments -n legions-of-minds
    echo ""
    
    # Services
    echo "=== Services ==="
    kubectl get svc -A | grep LoadBalancer
  
  verify-kubectl-access.sh: |
    #!/bin/bash
    # Test if kubectl is working from outside cluster
    
    echo "=== kubectl Access Test ==="
    
    # Try to list nodes
    kubectl get nodes &>/dev/null
    if [ $? -eq 0 ]; then
        echo "STATUS: WORKING"
        echo "ACCESS: AUTHENTICATED"
        kubectl version --short
    else
        echo "STATUS: BROKEN"
        echo "ACCESS: DENIED"
        echo "ERROR: Cannot reach cluster"
    fi

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 4: AUDIT LOGGING
# Tracks all AI node access for security
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: ssh-gateway
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/ai-access.log
      pos_file /var/log/ai-access.log.pos
      tag ai.access
      <parse>
        @type regexp
        expression /^(?<time>[^ ]+) \| (?<event>[^ ]+) \| (?<user>[^ ]+) \| (?<command>.+)$/
        time_key time
        time_format %Y-%m-%dT%H:%M:%S%z
      </parse>
    </source>
    
    <match ai.access>
      @type copy
      <store>
        @type stdout
      </store>
      <store>
        @type file
        path /var/log/ai-audit
        <buffer>
          timekey 1d
          timekey_wait 10m
        </buffer>
      </store>
    </match>

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: audit-logger
  namespace: ssh-gateway
spec:
  selector:
    matchLabels:
      app: audit-logger
  template:
    metadata:
      labels:
        app: audit-logger
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd:v1.16-1
        volumeMounts:
        - name: logs
          mountPath: /var/log
        - name: fluentd-config
          mountPath: /fluentd/etc
      volumes:
      - name: logs
        hostPath:
          path: /var/log/ssh-gateway
      - name: fluentd-config
        configMap:
          name: fluentd-config

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 5: STATE VERIFICATION API
# HTTP API for AI nodes to query without SSH
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: verification-api
  namespace: ssh-gateway
data:
  app.py: |
    from flask import Flask, jsonify
    import subprocess
    import json
    
    app = Flask(__name__)
    
    @app.route('/verify/deployment/<namespace>/<name>')
    def verify_deployment(namespace, name):
        """Verify deployment status"""
        try:
            result = subprocess.run(
                ['kubectl', 'get', 'deployment', name, '-n', namespace, '-o', 'json'],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0:
                deployment = json.loads(result.stdout)
                return jsonify({
                    'status': 'deployed',
                    'ready': deployment['status'].get('readyReplicas', 0),
                    'desired': deployment['spec']['replicas'],
                    'location': 'in-cluster'
                })
            else:
                return jsonify({
                    'status': 'not_deployed',
                    'location': 'not-in-cluster'
                })
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    
    @app.route('/verify/cluster/health')
    def cluster_health():
        """Overall cluster health"""
        try:
            nodes = subprocess.run(['kubectl', 'get', 'nodes', '-o', 'json'], 
                                   capture_output=True, text=True, timeout=10)
            pods = subprocess.run(['kubectl', 'get', 'pods', '-A', '-o', 'json'],
                                  capture_output=True, text=True, timeout=10)
            
            nodes_data = json.loads(nodes.stdout)
            pods_data = json.loads(pods.stdout)
            
            return jsonify({
                'nodes': {
                    'total': len(nodes_data['items']),
                    'ready': sum(1 for n in nodes_data['items'] 
                                if any(c['type'] == 'Ready' and c['status'] == 'True' 
                                      for c in n['status']['conditions']))
                },
                'pods': {
                    'total': len(pods_data['items']),
                    'running': sum(1 for p in pods_data['items'] 
                                  if p['status']['phase'] == 'Running')
                }
            })
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    
    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=8080)

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: verification-api
  namespace: ssh-gateway
spec:
  replicas: 2
  selector:
    matchLabels:
      app: verification-api
  template:
    metadata:
      labels:
        app: verification-api
    spec:
      serviceAccountName: ssh-gateway-sa
      containers:
      - name: api
        image: python:3.11-slim
        command:
        - /bin/sh
        - -c
        - |
          pip install flask
          apt-get update && apt-get install -y kubectl
          python /app/app.py
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: app
          mountPath: /app
      volumes:
      - name: app
        configMap:
          name: verification-api

---
apiVersion: v1
kind: Service
metadata:
  name: verification-api-svc
  namespace: ssh-gateway
spec:
  type: ClusterIP
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    app: verification-api

---
# ═══════════════════════════════════════════════════════════
# USAGE INSTRUCTIONS
# ═══════════════════════════════════════════════════════════

# Deploy the gateway:
# kubectl apply -f bootstrap/k8s/ssh-gateway.yaml

# Get the external IP:
# kubectl get svc -n ssh-gateway ssh-gateway-svc

# Generate AI node keys:
# ssh-keygen -t ed25519 -f claude-prime.key -C "claude-prime@strategickhaos.ai"
# ssh-keygen -t ed25519 -f gpt-5.1.key -C "gpt-5.1@strategickhaos.ai"
# ssh-keygen -t ed25519 -f grok-4.1.key -C "grok-4.1@strategickhaos.ai"

# Add public keys to ConfigMap and reapply

# AI nodes connect:
# ssh -i claude-prime.key -p 2222 ainode@<EXTERNAL_IP> "kubectl get pods -A"
# ssh -i claude-prime.key -p 2222 ainode@<EXTERNAL_IP> "verify-deployment.sh discord-bot"

# Or use HTTP API:
# curl http://<API_IP>:8080/verify/deployment/legions-of-minds/discord-bot
# curl http://<API_IP>:8080/verify/cluster/health

# ═══════════════════════════════════════════════════════════
# END OF KUBERNETES SSH GATEWAY
# 
# This is unprecedented: AI nodes with direct cluster access
# for verification. They can:
# - SSH in with their own keys
# - Run kubectl commands (read-only)
# - Verify deployment state
# - Check cluster health
# - All logged and audited
# 
# Multi-AI consensus via direct interrogation.
# Something the world has never seen.
# ═══════════════════════════════════════════════════════════
