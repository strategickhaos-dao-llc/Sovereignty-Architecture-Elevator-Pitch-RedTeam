# ═══════════════════════════════════════════════════════════
# KUBERNETES SSH GATEWAY — AI-VERIFIED STATE ORACLE
# Allows AI nodes to SSH into cluster and verify deployment state
# Something the world has never seen: Multi-AI consensus via direct cluster access
# ═══════════════════════════════════════════════════════════

---
apiVersion: v1
kind: Namespace
metadata:
  name: ssh-gateway
  labels:
    architect: strategickhaos
    increment: "3449"
    purpose: "AI node verification access"

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 1: SSH BASTION POD
# Entry point for AI nodes to verify cluster state
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: ssh-gateway-config
  namespace: ssh-gateway
data:
  sshd_config: |
    # SSH daemon config for AI node access
    Port 2222
    Protocol 2
    HostKey /etc/ssh/ssh_host_rsa_key
    HostKey /etc/ssh/ssh_host_ed25519_key
    
    # Security
    PermitRootLogin no
    PasswordAuthentication no
    PubkeyAuthentication yes
    AuthorizedKeysFile /home/ainode/.ssh/authorized_keys
    
    # AI node restrictions
    AllowUsers ainode
    MaxAuthTries 3
    MaxSessions 5
    
    # Logging for audit trail
    SyslogFacility AUTH
    LogLevel VERBOSE
    
    # Force command wrapper (restricts what AI can run)
    ForceCommand /usr/local/bin/verify-wrapper.sh
    
  verify-wrapper.sh: |
    #!/bin/bash
    # Wrapper that logs all AI node commands and restricts to safe operations
    set -euo pipefail
    
    # Log entry (escape command for safe logging)
    printf '%s | AI_NODE_ACCESS | USER=%s | CMD=%s\n' "$(date -Iseconds)" "$USER" "$SSH_ORIGINAL_COMMAND" >> /var/log/ai-access.log
    
    # Validate command is not empty
    if [ -z "${SSH_ORIGINAL_COMMAND:-}" ]; then
        echo "ERROR: No command provided"
        exit 1
    fi
    
    # Extract first word (command) safely
    CMD_WORD=$(echo "$SSH_ORIGINAL_COMMAND" | awk '{print $1}')
    
    # Allowed commands (exact match with word boundary)
    case "$CMD_WORD" in
        kubectl|grep|cat|ls|ps|df|free|uptime|date)
            # Additional safety: restrict kubectl to read-only subcommands
            if [ "$CMD_WORD" = "kubectl" ]; then
                KUBECTL_SUBCMD=$(echo "$SSH_ORIGINAL_COMMAND" | awk '{print $2}')
                case "$KUBECTL_SUBCMD" in
                    get|describe|logs|top|version|cluster-info|api-resources)
                        # Safe read-only kubectl commands - execute via array
                        read -r -a CMD_ARRAY <<< "$SSH_ORIGINAL_COMMAND"
                        "${CMD_ARRAY[@]}"
                        ;;
                    *)
                        echo "ERROR: kubectl subcommand not allowed: $KUBECTL_SUBCMD"
                        echo "Allowed: get, describe, logs, top, version, cluster-info, api-resources"
                        exit 1
                        ;;
                esac
            else
                # Execute non-kubectl commands via array
                read -r -a CMD_ARRAY <<< "$SSH_ORIGINAL_COMMAND"
                "${CMD_ARRAY[@]}"
            fi
            ;;
        *)
            echo "ERROR: Command not allowed: $CMD_WORD"
            echo "Allowed: kubectl (get/describe/logs/top), grep, cat, ls, ps, df, free, uptime, date"
            exit 1
            ;;
    esac
  
  ai-nodes.pub: |
    # Public keys for AI nodes
    # Each AI node gets its own key pair
    # 
    # IMPORTANT: Replace these placeholder entries with actual public keys!
    # Generate keys with: ssh-keygen -t ed25519 -f <node-name>.key -C "<node>@strategickhaos.ai"
    # Then add the .pub file contents below
    #
    # Example format (replace with actual keys):
    # ssh-ed25519 AAAA... claude-prime@strategickhaos.ai
    #
    # Placeholder entries (replace with real keys before deployment):
    # claude-prime@strategickhaos.ai - REPLACE_WITH_PUBLIC_KEY
    # gpt-5.1@strategickhaos.ai - REPLACE_WITH_PUBLIC_KEY
    # grok-4.1@strategickhaos.ai - REPLACE_WITH_PUBLIC_KEY
    # athena@strategickhaos.ai - REPLACE_WITH_PUBLIC_KEY
    # lyra@strategickhaos.ai - REPLACE_WITH_PUBLIC_KEY
    # nova@strategickhaos.ai - REPLACE_WITH_PUBLIC_KEY
    # ipower@strategickhaos.ai - REPLACE_WITH_PUBLIC_KEY

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ssh-gateway
  namespace: ssh-gateway
  labels:
    app: ssh-gateway
spec:
  replicas: 2  # High availability
  selector:
    matchLabels:
      app: ssh-gateway
  template:
    metadata:
      labels:
        app: ssh-gateway
        genesis-increment: "3449"
    spec:
      serviceAccountName: ssh-gateway-sa
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: sshd
        image: lscr.io/linuxserver/openssh-server:latest
        ports:
        - name: ssh
          containerPort: 2222
        env:
        - name: PUID
          value: "1000"
        - name: PGID
          value: "1000"
        - name: TZ
          value: "America/Chicago"
        - name: PUBLIC_KEY_FILE
          value: "/config/.ssh/authorized_keys"
        - name: USER_NAME
          value: "ainode"
        - name: SUDO_ACCESS
          value: "false"
        volumeMounts:
        - name: ssh-config
          mountPath: /config/ssh_host_keys
        - name: authorized-keys
          mountPath: /config/.ssh
          readOnly: true
        - name: verify-wrapper
          mountPath: /usr/local/bin
          readOnly: true
        - name: logs
          mountPath: /var/log
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          tcpSocket:
            port: 2222
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 2222
          initialDelaySeconds: 10
          periodSeconds: 5
      
      # Sidecar: kubectl proxy for AI nodes
      - name: kubectl-proxy
        image: bitnami/kubectl:latest
        command:
        - /bin/sh
        - -c
        - |
          # Make kubectl available to SSH users
          # Uses default service account token mounting
          kubectl proxy --port=8001 &
          tail -f /dev/null
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
      
      volumes:
      - name: ssh-config
        emptyDir: {}
      - name: authorized-keys
        configMap:
          name: ssh-gateway-config
          items:
          - key: ai-nodes.pub
            path: authorized_keys
            mode: 0600
      - name: verify-wrapper
        configMap:
          name: ssh-gateway-config
          items:
          - key: verify-wrapper.sh
            path: verify-wrapper.sh
            mode: 0755
      - name: logs
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: ssh-gateway-svc
  namespace: ssh-gateway
  labels:
    app: ssh-gateway
  annotations:
    # SECURITY: Configure LoadBalancer to restrict source IPs
    # Uncomment and modify for your cloud provider:
    # service.beta.kubernetes.io/aws-load-balancer-source-ranges: "10.0.0.0/8"
    # service.beta.kubernetes.io/azure-load-balancer-internal: "true"
    # cloud.google.com/load-balancer-type: "Internal"
spec:
  type: LoadBalancer  # Exposes SSH to external AI nodes (restrict with annotations above)
  ports:
  - name: ssh
    port: 2222
    targetPort: 2222
    protocol: TCP
  selector:
    app: ssh-gateway

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 2: RBAC FOR SSH GATEWAY
# Grants read-only cluster access to AI nodes
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ServiceAccount
metadata:
  name: ssh-gateway-sa
  namespace: ssh-gateway

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: ai-node-verifier
rules:
# Read-only access to verify deployment state
- apiGroups: [""]
  resources: ["pods", "services", "nodes", "configmaps"]
  verbs: ["get", "list", "watch"]

- apiGroups: ["apps"]
  resources: ["deployments", "replicasets", "statefulsets"]
  verbs: ["get", "list", "watch"]

- apiGroups: ["batch"]
  resources: ["jobs", "cronjobs"]
  verbs: ["get", "list", "watch"]

# Log access for debugging
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get", "list"]

# Metrics access
- apiGroups: ["metrics.k8s.io"]
  resources: ["pods", "nodes"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ssh-gateway-rb
subjects:
- kind: ServiceAccount
  name: ssh-gateway-sa
  namespace: ssh-gateway
roleRef:
  kind: ClusterRole
  name: ai-node-verifier
  apiGroup: rbac.authorization.k8s.io

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 3: AI NODE CLIENT SCRIPTS
# Scripts AI nodes run to verify cluster state
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-verification-scripts
  namespace: ssh-gateway
data:
  verify-deployment.sh: |
    #!/bin/bash
    # Script AI nodes run to verify deployment state
    # Usage: ssh -i claude-prime.key ainode@gateway verify-deployment.sh discord-bot
    
    DEPLOYMENT_NAME=$1
    NAMESPACE=${2:-legions-of-minds}
    
    echo "=== Verifying Deployment: $DEPLOYMENT_NAME in $NAMESPACE ==="
    
    # Check if deployment exists
    kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" &>/dev/null
    if [ $? -ne 0 ]; then
        echo "STATUS: NOT_DEPLOYED"
        echo "LOCATION: NOT_IN_CLUSTER"
        exit 0
    fi
    
    # Get deployment status
    READY=$(kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" -o jsonpath='{.status.readyReplicas}')
    DESIRED=$(kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" -o jsonpath='{.spec.replicas}')
    
    echo "STATUS: DEPLOYED"
    echo "READY: $READY/$DESIRED"
    echo "LOCATION: IN_CLUSTER"
    
    # Get pod details
    echo ""
    echo "=== Pods ==="
    kubectl get pods -n "$NAMESPACE" -l "app=$DEPLOYMENT_NAME" -o wide
    
    # Get recent events
    echo ""
    echo "=== Recent Events ==="
    kubectl get events -n "$NAMESPACE" --field-selector involvedObject.name="$DEPLOYMENT_NAME" --sort-by='.lastTimestamp' | tail -5
  
  verify-cluster-health.sh: |
    #!/bin/bash
    # Comprehensive cluster health check
    
    echo "=== Cluster Health Report ==="
    echo "Timestamp: $(date -Iseconds)"
    echo ""
    
    # Node status
    echo "=== Nodes ==="
    kubectl get nodes -o wide
    echo ""
    
    # All pods status
    echo "=== Pods (All Namespaces) ==="
    kubectl get pods -A | grep -v "Running" | grep -v "Completed" || echo "All pods healthy"
    echo ""
    
    # Resource usage
    echo "=== Resource Usage ==="
    kubectl top nodes 2>/dev/null || echo "Metrics server not available"
    echo ""
    
    # Critical deployments
    echo "=== Critical Deployments ==="
    kubectl get deployments -n legions-of-minds
    echo ""
    
    # Services
    echo "=== Services ==="
    kubectl get svc -A | grep LoadBalancer
  
  verify-kubectl-access.sh: |
    #!/bin/bash
    # Test if kubectl is working from outside cluster
    
    echo "=== kubectl Access Test ==="
    
    # Try to list nodes
    kubectl get nodes &>/dev/null
    if [ $? -eq 0 ]; then
        echo "STATUS: WORKING"
        echo "ACCESS: AUTHENTICATED"
        kubectl version --short
    else
        echo "STATUS: BROKEN"
        echo "ACCESS: DENIED"
        echo "ERROR: Cannot reach cluster"
    fi

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 4: AUDIT LOGGING
# Tracks all AI node access for security
# ═══════════════════════════════════════════════════════════

---
# NOTE: Audit logging is handled by the SSH gateway pod's log volume
# For production, integrate with your existing log aggregation (Loki, Fluentd, etc.)
# The ai-access.log is written to /var/log/ai-access.log in the sshd container
# 
# Option 1: Use kubectl logs to view audit logs:
#   kubectl logs -n ssh-gateway -l app=ssh-gateway -c sshd | grep AI_NODE_ACCESS
#
# Option 2: Add a sidecar container in the ssh-gateway deployment to forward logs
#   to your central logging system (Loki, Elasticsearch, etc.)
#
# Option 3: Mount a PersistentVolume for log retention
#
# The fluentd DaemonSet below is provided as a template for Option 2.
# It requires proper volume sharing between pods or a centralized log path.

apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: ssh-gateway
data:
  fluent.conf: |
    # Template configuration for log forwarding
    # Customize based on your logging infrastructure
    <source>
      @type tail
      path /var/log/ai-access.log
      pos_file /var/log/ai-access.log.pos
      tag ai.access
      <parse>
        @type regexp
        expression /^(?<time>[^ ]+) \| (?<event>[^ ]+) \| (?<user>[^ ]+) \| (?<command>.+)$/
        time_key time
        time_format %Y-%m-%dT%H:%M:%S%z
      </parse>
    </source>
    
    <match ai.access>
      @type copy
      <store>
        @type stdout
      </store>
      <store>
        @type file
        path /var/log/ai-audit
        <buffer>
          timekey 1d
          timekey_wait 10m
        </buffer>
      </store>
    </match>

---
# ═══════════════════════════════════════════════════════════
# COMPONENT 5: STATE VERIFICATION API
# HTTP API for AI nodes to query without SSH
# ═══════════════════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: verification-api
  namespace: ssh-gateway
data:
  app.py: |
    from flask import Flask, jsonify, abort
    import subprocess
    import json
    import re
    
    app = Flask(__name__)
    
    # Kubernetes naming convention: lowercase, alphanumeric, hyphens, max 253 chars
    K8S_NAME_PATTERN = re.compile(r'^[a-z0-9]([-a-z0-9]*[a-z0-9])?$')
    MAX_NAME_LENGTH = 253
    
    def validate_k8s_name(name, param_name):
        """Validate Kubernetes resource name to prevent injection"""
        if not name or len(name) > MAX_NAME_LENGTH:
            abort(400, description=f"Invalid {param_name}: must be 1-{MAX_NAME_LENGTH} characters")
        if not K8S_NAME_PATTERN.match(name):
            abort(400, description=f"Invalid {param_name}: must be lowercase alphanumeric with hyphens")
        return name
    
    @app.route('/verify/deployment/<namespace>/<name>')
    def verify_deployment(namespace, name):
        """Verify deployment status"""
        # Validate inputs against Kubernetes naming conventions
        namespace = validate_k8s_name(namespace, 'namespace')
        name = validate_k8s_name(name, 'name')
        
        try:
            result = subprocess.run(
                ['kubectl', 'get', 'deployment', name, '-n', namespace, '-o', 'json'],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0:
                deployment = json.loads(result.stdout)
                return jsonify({
                    'status': 'deployed',
                    'ready': deployment['status'].get('readyReplicas', 0),
                    'desired': deployment['spec']['replicas'],
                    'location': 'in-cluster'
                })
            else:
                return jsonify({
                    'status': 'not_deployed',
                    'location': 'not-in-cluster'
                })
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    
    @app.route('/verify/cluster/health')
    def cluster_health():
        """Overall cluster health"""
        try:
            nodes = subprocess.run(['kubectl', 'get', 'nodes', '-o', 'json'], 
                                   capture_output=True, text=True, timeout=10)
            pods = subprocess.run(['kubectl', 'get', 'pods', '-A', '-o', 'json'],
                                  capture_output=True, text=True, timeout=10)
            
            nodes_data = json.loads(nodes.stdout)
            pods_data = json.loads(pods.stdout)
            
            return jsonify({
                'nodes': {
                    'total': len(nodes_data['items']),
                    'ready': sum(1 for n in nodes_data['items'] 
                                if any(c['type'] == 'Ready' and c['status'] == 'True' 
                                      for c in n['status']['conditions']))
                },
                'pods': {
                    'total': len(pods_data['items']),
                    'running': sum(1 for p in pods_data['items'] 
                                  if p['status']['phase'] == 'Running')
                }
            })
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    
    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=8080)

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: verification-api
  namespace: ssh-gateway
  annotations:
    # NOTE: For production, build a custom Docker image with flask and kubectl pre-installed
    # Example Dockerfile:
    #   FROM python:3.11-slim
    #   RUN pip install --no-cache-dir flask && \
    #       apt-get update && apt-get install -y --no-install-recommends curl && \
    #       curl -LO "https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" && \
    #       install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl && \
    #       rm kubectl && apt-get clean && rm -rf /var/lib/apt/lists/*
    #   COPY app.py /app/app.py
    #   CMD ["python", "/app/app.py"]
spec:
  replicas: 2
  selector:
    matchLabels:
      app: verification-api
  template:
    metadata:
      labels:
        app: verification-api
    spec:
      serviceAccountName: ssh-gateway-sa
      initContainers:
      # Use init container to install dependencies once, avoiding repeated downloads
      - name: install-deps
        image: python:3.11-slim
        command:
        - /bin/sh
        - -c
        - |
          pip install --no-cache-dir flask -t /deps
          apt-get update && apt-get install -y --no-install-recommends curl
          curl -LO "https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          install -o root -g root -m 0755 kubectl /deps/kubectl
        volumeMounts:
        - name: deps
          mountPath: /deps
      containers:
      - name: api
        image: python:3.11-slim
        command:
        - /bin/sh
        - -c
        - |
          export PYTHONPATH=/deps:$PYTHONPATH
          export PATH=/deps:$PATH
          python /app/app.py
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: app
          mountPath: /app
        - name: deps
          mountPath: /deps
      volumes:
      - name: app
        configMap:
          name: verification-api
      - name: deps
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: verification-api-svc
  namespace: ssh-gateway
spec:
  type: ClusterIP
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    app: verification-api

---
# ═══════════════════════════════════════════════════════════
# USAGE INSTRUCTIONS
# ═══════════════════════════════════════════════════════════

# Deploy the gateway:
# kubectl apply -f bootstrap/k8s/ssh-gateway.yaml

# Get the external IP:
# kubectl get svc -n ssh-gateway ssh-gateway-svc

# Generate AI node keys:
# ssh-keygen -t ed25519 -f claude-prime.key -C "claude-prime@strategickhaos.ai"
# ssh-keygen -t ed25519 -f gpt-5.1.key -C "gpt-5.1@strategickhaos.ai"
# ssh-keygen -t ed25519 -f grok-4.1.key -C "grok-4.1@strategickhaos.ai"

# Add public keys to ConfigMap and reapply

# AI nodes connect:
# ssh -i claude-prime.key -p 2222 ainode@<EXTERNAL_IP> "kubectl get pods -A"
# ssh -i claude-prime.key -p 2222 ainode@<EXTERNAL_IP> "verify-deployment.sh discord-bot"

# Or use HTTP API:
# curl http://<API_IP>:8080/verify/deployment/legions-of-minds/discord-bot
# curl http://<API_IP>:8080/verify/cluster/health

# ═══════════════════════════════════════════════════════════
# END OF KUBERNETES SSH GATEWAY
# 
# This is unprecedented: AI nodes with direct cluster access
# for verification. They can:
# - SSH in with their own keys
# - Run kubectl commands (read-only)
# - Verify deployment state
# - Check cluster health
# - All logged and audited
# 
# Multi-AI consensus via direct interrogation.
# Something the world has never seen.
# ═══════════════════════════════════════════════════════════
