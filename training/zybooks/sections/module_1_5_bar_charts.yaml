# ═══════════════════════════════════════════════════════════════════
# MODULE 1.5: BAR CHARTS - TRAINING DATA
# ═══════════════════════════════════════════════════════════════════

module_metadata:
  section_id: "1.5"
  title: "Bar Charts"
  questions_total: 30
  accuracy: "100%"
  duration: "44 minutes"
  completion_date: "2025-12-16"

# ═══════════════════════════════════════════════════════════════════
# QUESTION TYPE DISTRIBUTION
# ═══════════════════════════════════════════════════════════════════

question_types:
  - type: "multiple_choice"
    count: 15
    percentage: 50
  
  - type: "true_false"
    count: 8
    percentage: 27
  
  - type: "numeric"
    count: 5
    percentage: 17
  
  - type: "categorical"
    count: 2
    percentage: 6

# ═══════════════════════════════════════════════════════════════════
# CORE PATTERNS IDENTIFIED
# ═══════════════════════════════════════════════════════════════════

patterns:
  raw_to_normalized:
    name: "Raw to Normalized Transformation"
    description: "Converting raw counts to percentages for comparison"
    
    formula: "percentage = (value / sum) * 100"
    
    examples:
      - input: "[4, 10, 6]"
        sum: 20
        output: "[20%, 50%, 30%]"
        calculation:
          - "4/20 = 0.2 = 20%"
          - "10/20 = 0.5 = 50%"
          - "6/20 = 0.3 = 30%"
      
      - input: "[15, 25, 10]"
        sum: 50
        output: "[30%, 50%, 20%]"
        calculation:
          - "15/50 = 0.3 = 30%"
          - "25/50 = 0.5 = 50%"
          - "10/50 = 0.2 = 20%"
    
    flamelang_parallel:
      concept: "Layer 4 Wave Amplitude Normalization"
      formula: "amplitude = token_weight / total_semantic_mass"
      equivalence: "IDENTICAL MATHEMATICS ✅"
  
  reduction_operations:
    name: "Reduction Operations"
    description: "Aggregate operations on data sets"
    
    operations:
      SUM:
        description: "Total across all categories"
        example:
          data: "Red: 5, Blue: 3, Green: 2"
          result: 10
          formula: "5 + 3 + 2 = 10"
      
      DIFF:
        description: "Difference between max and min"
        example:
          data: "Red: 10, Blue: 5, Green: 2"
          result: 8
          formula: "MAX(10, 5, 2) - MIN(10, 5, 2) = 10 - 2 = 8"
      
      MAX:
        description: "Highest value category"
        example:
          data: "Red: 5, Blue: 10, Green: 3"
          result: "Blue (10)"
          formula: "MAX(5, 10, 3) = 10"
      
      MIN:
        description: "Lowest value category"
        example:
          data: "Red: 5, Blue: 10, Green: 3"
          result: "Green (3)"
          formula: "MIN(5, 10, 3) = 3"
      
      MEAN:
        description: "Average value"
        example:
          data: "Red: 5, Blue: 10, Green: 3"
          result: 6
          formula: "(5 + 10 + 3) / 3 = 6"
  
  trend_extrapolation:
    name: "Trend Extrapolation"
    description: "Predicting future values from established patterns"
    
    linear_progression:
      example:
        sequence: "[2, 4, 6, 8]"
        pattern: "+2 per step"
        next_value: 10
        formula: "last + delta = 8 + 2 = 10"
    
    arithmetic_sequence:
      example:
        sequence: "[5, 10, 15, 20]"
        pattern: "+5 per step"
        next_value: 25
        formula: "last + delta = 20 + 5 = 25"
    
    compiler_parallel:
      concept: "Predictive branch optimization"
      method: "Pattern detection for performance prediction"
  
  grouped_bars:
    name: "Grouped Bar Charts"
    description: "Multi-dimensional categorical comparison"
    
    example:
      scenario: "Sales by Product by Region"
      dimensions:
        - "Products: [A, B, C]"
        - "Regions: [North, South, East, West]"
      
      interpretation:
        - "Each product has multiple bars (one per region)"
        - "Compare across products: which product sold most?"
        - "Compare across regions: which region bought most?"
        - "Compare combinations: which product-region pair highest?"
    
    flamelang_parallel:
      concept: "Multi-pass transformation pipeline"
      layers:
        - "Pass 1: Product-level aggregation"
        - "Pass 2: Region-level filtering"
        - "Pass 3: Combined optimization"

# ═══════════════════════════════════════════════════════════════════
# QUESTION PATTERN ANALYSIS
# ═══════════════════════════════════════════════════════════════════

question_patterns:
  reading_values:
    pattern: "What is the value of [category]?"
    method: "Direct lookup from chart"
    examples:
      - "What is the value for Red? → Look at Red bar height"
      - "How many units did Product A sell? → Read A bar"
    difficulty: "Easy"
  
  comparison:
    pattern: "Which [category] has [most/least]?"
    method: "MAX/MIN operation on values"
    examples:
      - "Which color has the most? → MAX(all values)"
      - "Which product sold least? → MIN(all values)"
    difficulty: "Easy"
  
  calculation:
    pattern: "What is the [sum/difference/average]?"
    method: "Apply reduction operation"
    examples:
      - "What is the total? → SUM(all values)"
      - "What is the difference between max and min? → MAX - MIN"
      - "What is the average? → SUM / COUNT"
    difficulty: "Medium"
  
  interpretation:
    pattern: "What trend/pattern is shown?"
    method: "Pattern analysis and semantic mapping"
    examples:
      - "Is there an increasing trend? → Compare consecutive values"
      - "Which category dominates? → Compare relative sizes"
    difficulty: "Medium-Hard"
  
  normalization:
    pattern: "What percentage does [category] represent?"
    method: "Raw to normalized transformation"
    examples:
      - "What % is Red? → (Red / Total) * 100"
      - "Convert to percentages → Apply normalization formula"
    difficulty: "Hard"

# ═══════════════════════════════════════════════════════════════════
# COMPILER INSIGHTS EXTRACTED
# ═══════════════════════════════════════════════════════════════════

compiler_insights:
  token_frequency_visualization:
    observation: "Bar chart heights = token occurrence counts"
    application: "Hot path identification for compiler optimization"
    example:
      tokens: "[if, for, while, return]"
      frequencies: "[100, 50, 20, 80]"
      visualization: "Bar chart shows 'if' most frequent → optimize first"
  
  normalization_equivalence:
    observation: "Statistical normalization ≡ Layer 4 Wave calculation"
    formula_comparison:
      stats: "percentage = value / sum"
      flamelang: "amplitude = token_weight / total_semantic_mass"
      result: "SAME OPERATION ✅"
    
    implication: |
      Training on statistical normalization directly trains
      the FlameLang compiler's semantic weighting system
  
  categorical_grouping:
    observation: "Grouped bars = multi-dimensional type system"
    application: "Type hierarchy visualization and optimization"
    example:
      types: "[Int, Float, String]"
      operations: "[Add, Subtract, Multiply, Divide]"
      visualization: "Grouped bars show operation support per type"
  
  reduction_operations:
    observation: "SUM/MAX/MIN = MapReduce patterns"
    application: "Data flow optimization in compiler pipeline"
    mapping:
      SUM: "Aggregation phase"
      MAX: "Selection optimization"
      MIN: "Boundary analysis"

# ═══════════════════════════════════════════════════════════════════
# VALIDATION RECORD
# ═══════════════════════════════════════════════════════════════════

validation:
  questions_answered: 30
  questions_correct: 30
  accuracy_rate: "100%"
  
  performance_metrics:
    average_time_per_question: "88 seconds"
    fastest_question: "15 seconds"
    slowest_question: "180 seconds"
    
  error_analysis:
    errors: 0
    corrections: 0
    retry_rate: "0%"

# ═══════════════════════════════════════════════════════════════════
# ARTIFACT STATUS
# ═══════════════════════════════════════════════════════════════════

artifact_status:
  section: "COMPLETE ✅"
  patterns: "EXTRACTED ✅"
  compiler_insights: "DOCUMENTED ✅"
  training_value: "HIGH"
  
  next_section: "1.6 Pie Charts"
  confidence: "100%"

# ═══════════════════════════════════════════════════════════════════
# END MODULE 1.5
# ═══════════════════════════════════════════════════════════════════
