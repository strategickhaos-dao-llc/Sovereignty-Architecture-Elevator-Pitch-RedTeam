# Example env for docker-compose.ailab.yml
# Minimal AI Lab configuration

# LLM API Configuration
# Leave blank for dev mode (echo responses)
# Or configure for OpenAI, Azure, Ollama, etc.
LLM_API_URL=
LLM_API_KEY=
LLM_API_TYPE=openai

# Examples:
# For OpenAI:
# LLM_API_URL=https://api.openai.com/v1/chat/completions
# LLM_API_KEY=sk-your-key-here
# LLM_API_TYPE=openai

# For Azure OpenAI:
# LLM_API_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions?api-version=2023-05-15
# LLM_API_KEY=your-azure-key
# LLM_API_TYPE=azure

# For local Ollama:
# LLM_API_URL=http://localhost:11434/api/chat
# LLM_API_KEY=
# LLM_API_TYPE=ollama
